{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25fd1f0b",
   "metadata": {},
   "source": [
    "Key references:\n",
    "- [How to invoke the tool with ToolCall to return `Artifacts`](https://python.langchain.com/docs/how_to/tool_artifacts/#invoking-the-tool-with-toolcall)\n",
    "    - https://js.langchain.com/docs/how_to/tool_artifacts/#invoking-the-tool-with-toolcall\n",
    "- [Hiding arguments from the model](https://python.langchain.com/docs/how_to/tool_runtime/#other-ways-of-annotating-args)\n",
    "- [DeepMind's DeepResearch implementation with Langgraph](https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart#)\n",
    "- [Langchain's deepresearch example](https://github.com/langchain-ai/open_deep_research#)\n",
    "    - define `from_runnable_config` to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1298b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Any, List, Literal, Optional, Tuple\n",
    "\n",
    "from langchain_core.callbacks import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "from langchain_core.tools import BaseTool, InjectedToolArg\n",
    "from langchain_core.tools.base import ArgsSchema\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd3def58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrieverInput(BaseModel):\n",
    "    query: str = Field(description=\"User query for information retrieval\")\n",
    "    retrieval_top_k: Annotated[int, InjectedToolArg] = Field(\n",
    "        5, \n",
    "        description=\"Number of most relevant records to retrieve from the vector store\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ca1ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "class RetrieverTool(BaseTool):\n",
    "    \"\"\"A stateful retriever tool that holds the vector retrieval service.\"\"\"\n",
    "    name: str = \"Information Retrieval Tool\"\n",
    "    description: str = \"Retrieves most relevant records from the vector store for the provided query.\"\n",
    "    args_schema: Optional[ArgsSchema] = RetrieverInput\n",
    "    # return_direct: bool = True\n",
    "    response_format: Literal[\"content\", \"content_and_artifact\"] = \"content_and_artifact\"\n",
    "    \n",
    "    client: str = Field(\"hello\", description=\"This can be initialized client/service\")\n",
    "\n",
    "    \n",
    "    def _run(self, query: str, retrieval_top_k: int, config: RunnableConfig) -> Tuple[List[str], Any]:\n",
    "        \"\"\"Retrieves most relevant records from the vector store for the provided query.\"\"\"\n",
    "        # artifact = self.vector_retrieval_service.vector_store.similarity_search(\n",
    "        #     query=query,\n",
    "        #     k=self.top_k,\n",
    "        # )\n",
    "        \n",
    "        # response = [res.data for res in artifact]\n",
    "        # return response, artifact\n",
    "        # top_k = config[\"configurable\"][\"top_k\"]\n",
    "        response, artifact = [query.upper()]*retrieval_top_k, {\"metadata\": \"example_metadata\"}\n",
    "        return response, artifact\n",
    "    \n",
    "    async def _arun(self, query: str, config: RunnableConfig) -> Tuple[List[str], Any]:\n",
    "        \"\"\"Asynchronous version of the run method.\"\"\"\n",
    "        # Simulating async behavior\n",
    "        ...\n",
    "\n",
    "config = {\"configurable\": {\"top_k\": 3}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96be077a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yooo'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RetrieverTool(client=\"yooo\").client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec102070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WHAT IS LANGCHAIN?', 'WHAT IS LANGCHAIN?', 'WHAT IS LANGCHAIN?']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool = RetrieverTool(\n",
    "    response_format=\"content_and_artifact\",\n",
    "    client=\"example_client\"\n",
    ")\n",
    "\n",
    "retriever_tool.invoke(\n",
    "    input={\"query\": \"What is LangChain?\", \"retrieval_top_k\": 3}, \n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b33071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content=['WHAT IS LANGCHAIN?', 'WHAT IS LANGCHAIN?', 'WHAT IS LANGCHAIN?'], name='Information Retrieval Tool', tool_call_id='123', artifact={'metadata': 'example_metadata'})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import ToolCall\n",
    "\n",
    "# NOTE: only when input is ToolCall, a TypedDict, artifacts will be returned \n",
    "\n",
    "retriever_tool.invoke(\n",
    "    input=ToolCall(\n",
    "        name=\"Information Retrieval Tool\",\n",
    "        args={\"query\": \"What is LangChain?\", \"retrieval_top_k\": 3},\n",
    "        id=\"123\",\n",
    "        type=\"tool_call\",\n",
    "    ),\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f57821",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = RetrieverTool(client=\"example_client\")\n",
    "retriever_tool.get_input_schema().schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe04fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool.tool_call_schema().schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9e70356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "retriever_node = ToolNode([RetrieverTool()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c965616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Create a message-based input instead of a string\n",
    "message_input = AIMessage(\n",
    "    content=\"What is LangChain?\",\n",
    "    tool_calls=[\n",
    "    {\n",
    "        \"name\": \"Information Retrieval Tool\",\n",
    "        \"args\": {\n",
    "            \"query\": \"What is LangChain?\"\n",
    "        },\n",
    "        \"id\": \"tool_call_1\"\n",
    "    },\n",
    "])\n",
    "\n",
    "# Create API style message input\n",
    "\n",
    "node_output = retriever_node.invoke(\n",
    "    input={\n",
    "        \"messages\": [message_input]\n",
    "    },\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "209a40f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content='[\"WHAT IS LANGCHAIN?\", \"WHAT IS LANGCHAIN?\", \"WHAT IS LANGCHAIN?\"]', name='Information Retrieval Tool', tool_call_id='tool_call_1', artifact={'metadata': 'example_metadata'})]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c22defb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='[\"WHAT IS LANGCHAIN?\", \"WHAT IS LANGCHAIN?\", \"WHAT IS LANGCHAIN?\"]', name='Information Retrieval Tool', tool_call_id='tool_call_1', artifact={'metadata': 'example_metadata'})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_output[\"messages\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55ec4dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"WHAT IS LANGCHAIN?\", \"WHAT IS LANGCHAIN?\", \"WHAT IS LANGCHAIN?\"]'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_output[\"messages\"][0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72d37556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': 'example_metadata'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_output[\"messages\"][0].artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f32411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_hub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
