{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pyspark_compactor.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"QAsdVMpbEiO3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636651303767,"user_tz":0,"elapsed":57122,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}},"outputId":"560881eb-8049-42ff-ff4e-f4499d8c94a6"},"source":["! pip install pyspark[sql]"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark[sql]\n","  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n","\u001b[K     |████████████████████████████████| 281.3 MB 19 kB/s \n","\u001b[?25hCollecting py4j==0.10.9.2\n","  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n","\u001b[K     |████████████████████████████████| 198 kB 42.5 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from pyspark[sql]) (1.1.5)\n","Requirement already satisfied: pyarrow>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pyspark[sql]) (3.0.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->pyspark[sql]) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->pyspark[sql]) (2018.9)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->pyspark[sql]) (1.19.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.2->pyspark[sql]) (1.15.0)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=a7fd93ed15bcaef27a38b498735805baa0853bdbd89c850d7853738eb13312dd\n","  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"]}]},{"cell_type":"code","metadata":{"id":"lIYdn1woOS1n","executionInfo":{"status":"ok","timestamp":1636651304375,"user_tz":0,"elapsed":614,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}}},"source":["from typing import Optional\n","\n","# from pyspark.sql.session import SparkSession\n","\n","from pyspark.sql.types import (\n","    ArrayType,\n","    BooleanType,\n","    NumericType,\n","    StringType,\n","    StructField,\n","    StructType,\n",")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"5pt4O_KhEbB_","executionInfo":{"status":"ok","timestamp":1636651305160,"user_tz":0,"elapsed":4,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}}},"source":["def _create_entity(dt: int, *, id: str, version=\"0.0.1\", **attrs):\n","        return {\n","            \"_dt\": _dt(dt),\n","            \"id\": id,\n","            \"version\": version,\n","            **attrs,\n","        }\n","\n","def _create_schema(**fields):\n","    schema = StructType()\n","    for k, v in fields.items():\n","        schema.add(k, v)\n","    return schema\n","\n","\n","def _v(value: Optional[str]) -> dict:\n","    return {\"value\": value}\n","\n","\n","def _dt(secs: int) -> str:\n","    return f\"2020-01-01T00:00:{secs:02}.0000\"\n","\n","\n","def _ns(*attrs):\n","    ns = StructType()\n","    for key in attrs:\n","        ns.add(key, field_type)\n","    return ns\n","\n","\n","field_type = StructType(\n","    [\n","        # Value\n","        StructField(\"value\", StringType(), nullable=True)\n","        # Any additional metadata\n","    ]\n",")\n","\n","EVENT_SCHEMA = {\n","    \"_dt\": StringType(),\n","    \"version\": StringType(),\n","    \"id\": StringType(),\n","}\n","\n","COMPACTED_SCHEMA = {\n","    \"version\": StringType(),\n","    \"id\": StringType(),\n","    \"date_created\": StringType(),\n","    \"date_updated\": StringType(),\n","}\n","\n","UNION_SCHEMA = {\n","    \"_dt\": StringType(),\n","    \"_compacted\": BooleanType(),\n","    \"date_created\": StringType(),\n","    \"date_updated\": StringType(),\n","    \"id\": StringType(),\n","    \"version\": StringType(),\n","}"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GG9eB1xPH3cZ"},"source":["## Compactor"]},{"cell_type":"code","metadata":{"id":"c8xV-IK_STiL","executionInfo":{"status":"ok","timestamp":1636651305161,"user_tz":0,"elapsed":4,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}}},"source":["from datetime import datetime\n","from typing import NewType, Union, overload\n","\n","class Action:\n","    T = NewType(\"T\", str)\n","    DELETE = T(\"delete\")\n","    REPLACE = T(\"replace\")\n","\n","\n","def recursively_merge_attributes(base, update):\n","    if update is None:\n","        # Updates are None if the event didn't set that attribute\n","        return base\n","    if not isinstance(base, dict):\n","        # Base is None if it's a part of the skeleton\n","        # If base is another non-dict value we can't merge, so the update wins\n","        # can't just `return update` here, need to handle possible `c_action` below\n","        base = {}\n","    if not isinstance(update, dict):\n","        # can't merge so update wins\n","        return update\n","\n","    merged = {}\n","\n","    if update.get(\"c_action\") == Action.REPLACE:\n","        base = {}\n","\n","    # NOTE: top level deletion is enabled\n","    if update.get(\"c_action\") == Action.DELETE:\n","        return {}\n","\n","    # NOTE: top level expiry is enabled\n","    exipire_dt = update.get(\"c_expire_dt\", \"9999-12-31T23:59:59.999999\")\n","    if exipire_dt and datetime.fromisoformat(exipire_dt) <= datetime.now():\n","        return {}\n","\n","    for key in (base.keys() | update.keys()) - {\"c_action\"}:\n","        nested_update = update.get(key)\n","\n","        if isinstance(nested_update, dict):\n","            to_delete = nested_update.get(\"c_action\") == Action.DELETE\n","            exipire_dt = nested_update.get(\"c_expire_dt\", \"9999-12-31T23:59:59.999999\")\n","            to_expire = exipire_dt and datetime.fromisoformat(exipire_dt) <= datetime.now()\n","\n","            if to_delete or to_expire:\n","                continue\n","\n","        merged[key] = recursively_merge_attributes(base.get(key), nested_update)\n","    return merged\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"QcEfcRDZSXsT","executionInfo":{"status":"ok","timestamp":1636651312087,"user_tz":0,"elapsed":6930,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}}},"source":["import logging\n","from typing import Dict, List, Optional, Tuple, Union\n","\n","from pyspark.sql import DataFrame, Row, functions as F\n","from pyspark.sql.session import SparkSession\n","from pyspark.sql.types import ArrayType, StringType, StructType\n","\n","log = logging.getLogger(__name__)\n","\n","EntityAttributesItem = Union[str, None, dict]\n","EntityAttributes = Dict[str, EntityAttributesItem]\n","AttributeSkeleton = Dict[str, Union[None, dict]]\n","\n","spark_session = SparkSession.builder.getOrCreate()\n","# spark = SparkSession.builder.getOrCreate()\n","\n","def get_attributes_skeleton(schema: StructType) -> AttributeSkeleton:\n","    \"\"\"\n","    Constructs an empty dictionary that can contain every possible\n","    attribute in schema.\n","    Used to simplify merging new and old schemae together\n","    \"\"\"\n","    skeleton: AttributeSkeleton = {}\n","    for field in schema:\n","        if isinstance(field.dataType, StructType):\n","            skeleton[field.name] = get_attributes_skeleton(field.dataType)\n","        else:\n","            skeleton[field.name] = None\n","    return skeleton\n","\n","\n","def merge_schemas(base: StructType, update: StructType) -> Tuple[StructType, bool]:\n","    \"\"\"\n","    Creates a new schema that contains all the attributes in both passed\n","    schemas, so we can easily merge events into compacted entities.\n","\n","    There is no reasonable way to preserve field ordering while doing this,\n","    so we just alphabetise the fields so that everything is consistent.\n","    It also looks nicer when debugging.\n","\n","    Field order is also important when mutating dataframes, which we\n","    currently don't do, but if we start doing it having everything\n","    alphabetical will help with that.\n","\n","    Also, it returns a convenience sentinel to let you know if the compacted\n","    entities need to be updated to add a new field to them.\n","    \"\"\"\n","\n","    base_keys = set(base.fieldNames())\n","    update_keys = set(update.fieldNames())\n","    base_has_new_keys = bool(update_keys - base_keys)\n","\n","    ret = StructType()\n","\n","    for key in sorted(base_keys | update_keys):\n","        base_type = base[key].dataType if key in base_keys else None\n","        update_type = update[key].dataType if key in update_keys else None\n","\n","        if base_type is None or update_type is None:\n","            new_type = base_type or update_type\n","            ret.add(key, new_type)\n","            continue\n","\n","        if type(base_type) != type(update_type):\n","            raise RuntimeError(\n","                \"Trying to merge invalid schemas: \"\n","                f\"Got a {type(update_type)} {key} but expected a {type(base_type)}!\"\n","            )\n","\n","        if isinstance(update_type, StructType):\n","            update_type, new_keys = merge_schemas(base_type, update_type)\n","            if new_keys:\n","                base_has_new_keys = True\n","\n","        if isinstance(update_type, ArrayType):\n","            update_sub_type = update_type.elementType\n","            base_sub_type = base_type.elementType\n","\n","            if type(base_sub_type) != type(update_sub_type):\n","                raise RuntimeError(\n","                    \"Trying to merge invalid schemas: \"\n","                    f\"Got a {type(update_sub_type)} {key} but expected a {type(base_sub_type)}!\"\n","                )\n","\n","            if isinstance(update_sub_type, StructType):\n","                update_sub_type, new_keys = merge_schemas(base_sub_type, update_sub_type)\n","                update_type = ArrayType(update_sub_type)\n","                if new_keys:\n","                    base_has_new_keys = True\n","\n","            # TODO: Arrays of arrays oh no this needs a huge refactor\n","            assert not isinstance(update_sub_type, ArrayType)\n","\n","        ret.add(key, update_type)\n","\n","    return ret, base_has_new_keys\n","\n","\n","def extract_entities(data: DataFrame) -> DataFrame:\n","    \"\"\"\n","    Extracts all the entities from the passed events, maintaining order.\n","    Does not de-duplicate\n","    \"\"\"\n","\n","    entity_columns = [f\"`{col}`\" for col in data.columns if not col.startswith(\"_\")]\n","\n","    return data.select(F.col(\"`_dt`\"), F.col(\"`_version`\").alias(\"version\"), *entity_columns)\n","\n","\n","def create_entity_union(\n","    spark_session: SparkSession, events: DataFrame, compacted: Optional[DataFrame]\n",") -> DataFrame:\n","    \"\"\"\n","    Joins the events and compacted data into one giant un-de-duplicated\n","    dataframe so they can be more easily compacted.\n","    \"\"\"\n","\n","    if \"date_created\" not in events.columns:\n","        events = events.withColumn(\"date_created\", F.lit(None).cast(StringType()))\n","    events = events.withColumn(\"date_updated\", F.col(\"_dt\"))\n","    events = events.withColumn(\"_compacted\", F.lit(False))\n","\n","    # Counting a dataframe can be extremely slow, so pull the first item and\n","    #  see if it exists.\n","    # This is merely fairly slow which is a huge improvement over .count()!\n","    if not compacted or compacted.first() is None:\n","        return events\n","\n","    # Compacted entities don't have a datetime since they're not events, so\n","    # make sure they have a datetime of \"0\" that will always sort before any\n","    # event to avoid suprises\n","    compacted = compacted.withColumn(\"_dt\", F.lit(\"0\"))\n","\n","    # Make it so we can find compacted entities easily\n","    compacted = compacted.withColumn(\"_compacted\", F.lit(True))\n","\n","    schema, update_compacted = merge_schemas(compacted.schema, events.schema)\n","    skeleton = get_attributes_skeleton(schema)\n","\n","    def fix_schema(row: Row) -> EntityAttributesItem:\n","        return recursively_merge_attributes(skeleton, row.asDict(recursive=True))\n","\n","    # Add all the missing fields to the events so we can merge them with the compacted\n","    events = spark_session.createDataFrame(events.rdd.map(fix_schema), schema)\n","    # Make sure compacted follows same schema as events\n","    compacted = spark_session.createDataFrame(compacted.rdd.map(fix_schema), schema)\n","\n","    return compacted.unionByName(events)\n","\n","\n","def do_compaction(data: Tuple[str, List[dict]]) -> dict:\n","    \"\"\"\n","    Accepts a list of entities, expected to be a compacted base & updated\n","    events (in arbitrary order)\n","\n","    The first argument is a tuple beacuse of how grouping works in RDDs. We\n","    could have a tiny map step before this one that removes the tuple, but I\n","    thought it would be more efficient to remove it here.\n","    \"\"\"\n","\n","    # Get rid of the grouping tuple\n","    events = data[1]\n","\n","    # # NOTE: events: [{compacted}, {new_events}]\n","    # # Short circuit for entities with no events\n","    # if len(events) == 1 and events[0][\"_compacted\"]:\n","    #     return events[0]\n","\n","    events.sort(key=lambda a: a[\"_dt\"])\n","\n","    base = events[0]  # compacted event\n","    ret: dict = {}\n","\n","    if base[\"_compacted\"]:\n","        if base[\"date_created\"] is not None:\n","            # Ensure no events can overwrite date_created\n","            # NOTE: overwrite `date_created` in the end\n","            events.append({\"date_created\": base[\"date_created\"]})\n","    else:\n","        # Invent a date_created for the new entity, though in such a way that\n","        # it can be easily overwritten by events\n","        ret[\"date_created\"] = base[\"_dt\"]\n","\n","    for update in events:\n","        \n","        ret = recursively_merge_attributes(ret, update)\n","        print(ret)\n","\n","    return ret\n","\n","\n","def _map_value(value: Row) -> dict:\n","    \"\"\"\n","    Turns the pyspark rows into something a bit more easy to work with\n","    \"\"\"\n","    return value.asDict(recursive=True)\n","\n","\n","Combiner = List[dict]\n","\n","\n","# The following functions are used by combineByKey to do distributed map/reduce\n","#  operations across multiple partitions.\n","# For more info, check out the docs:\n","# https://spark.apache.org/docs//2.4.3/api/python/pyspark.html#pyspark.RDD.combineByKey\n","def create_combiner(value: Row) -> Combiner:\n","    \"\"\"\n","    First map operation done per partition.\n","    In our case, we turn the value (a row) into a dict and then add it to a list\n","    \"\"\"\n","    return [_map_value(value)]\n","\n","\n","def merge_value(combiner: Combiner, value: Row) -> Combiner:\n","    \"\"\"\n","    Combined map/reduce operation on values in a partition.\n","\n","    `combiner` is the output of create_combiner and `value` is a raw unmapped value.\n","\n","    We convert it to a dict also, and then append it to the list.\n","\n","    We can't merge values yet as this is done in an arbitrary order and our\n","    code is order-dependant, so we're just building a list here.\n","    \"\"\"\n","    combiner.append(_map_value(value))\n","    return combiner\n","\n","\n","def merge_combiners(a: Combiner, b: Combiner) -> Combiner:\n","    \"\"\"\n","    Reduce operation between partitions.\n","\n","    In this case, we just smack the two lists together, though we could do\n","    other operations if we wanted.\n","\n","    Note that PySpark recommends modifying the first argument rather than\n","    creating a new list to avoid memory operations.\n","    \"\"\"\n","    a.extend(b)\n","    return a\n","\n","\n","def compact_entities(spark_session: SparkSession, union: DataFrame) -> DataFrame:\n","    \"\"\"\n","    Compacts all the entities in the passed dataframe, grouping by ID and compacting in date order.\n","    \"\"\"\n","\n","    # TODO: Is it worth spending the time to figure out if there are any\n","    #  duplicate entries in the first place?\n","    # We can skip an entire map/reduce step if nothing needs compacting...\n","    # (Also presumably once we've done that we can partition better??)\n","\n","    merged = (\n","        union.rdd\n","        # Group everything by ID.\n","        # Note that combineByKey only works if the dataset is two columns, so\n","        # we need to map it first\n","        .map(lambda entity: (entity[\"id\"], entity)).combineByKey(\n","            create_combiner, merge_value, merge_combiners\n","        )\n","        # Turn the groups back into entities\n","        .map(do_compaction)\n","    )\n","\n","    return spark_session.createDataFrame(merged, union.schema).drop(\"_dt\", \"_compacted\").dropna(\"any\", subset=\"id\")\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pLg21HVOBNv2"},"source":["## Examples"]},{"cell_type":"markdown","metadata":{"id":"SA-aTo5dBUfn"},"source":["### do_compaction"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mAGUvcfgY1Zq","executionInfo":{"status":"ok","timestamp":1636651312088,"user_tz":0,"elapsed":14,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}},"outputId":"6a73bc2f-4c5d-4167-9f93-9ce08a07ce8e"},"source":["events = [\n","            {\"_dt\": _dt(2), \"_compacted\": False, \"date_created\": None, \"foo\": None, \"bar\": \"3\", \"c_action\": \"delete\"},\n","            {\"_dt\": _dt(0), \"_compacted\": True, \"date_created\": _dt(0), \"foo\": \"1\", \"bar\": \"1\"},\n","            {\"_dt\": _dt(1), \"_compacted\": False, \"date_created\": None, \"foo\": \"2\", \"bar\": \"2\"},\n","        ]\n","compacted = do_compaction((\"\", events))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["{'foo': '1', '_compacted': True, '_dt': '2020-01-01T00:00:00.0000', 'date_created': '2020-01-01T00:00:00.0000', 'bar': '1'}\n","{'foo': '2', '_compacted': False, '_dt': '2020-01-01T00:00:01.0000', 'date_created': '2020-01-01T00:00:00.0000', 'bar': '2'}\n","{}\n","{'date_created': '2020-01-01T00:00:00.0000'}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-m7Tep5Y40S","executionInfo":{"status":"ok","timestamp":1636651312089,"user_tz":0,"elapsed":11,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}},"outputId":"05861333-23ac-4f7f-bf5d-09dba38838d8"},"source":["compacted"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'date_created': '2020-01-01T00:00:00.0000'}"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"bYNk1N34BXxs"},"source":["### compact_entities"]},{"cell_type":"code","metadata":{"id":"ivVuC5m_SbLD","executionInfo":{"status":"ok","timestamp":1636651351363,"user_tz":0,"elapsed":5858,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}}},"source":["union = spark_session.createDataFrame(\n","    [\n","        dict(\n","            _dt=_dt(4),\n","            id=\"foo\",\n","            version=\"1.0.0\",\n","            date_updated=_dt(4),\n","            live={\"foo\": _v(\"3\")},\n","        ),\n","        dict(\n","            _dt=_dt(3),\n","            id=\"foo\",\n","            version=\"1.0.0\",\n","            date_updated=_dt(3),\n","            live={\"foo\": _v(\"2\")},\n","        ),\n","        dict(\n","            _dt=\"0\",\n","            _compacted=True,\n","            id=\"foo\",\n","            version=\"1.0.0\",\n","            date_updated=_dt(2),\n","            date_created=_dt(1),\n","            live={\"foo\": _v(\"1\")},\n","        ),\n","        dict(\n","            _dt=\"0\",\n","            _compacted=True,\n","            id=\"chic\",\n","            version=\"1.0.0\",\n","            date_updated=_dt(2),\n","            date_created=_dt(1),\n","            c_action = \"delete\",\n","            # live={\"foo\": _v(\"1\"), \"c_expire_dt\": \"0001-01-01T00:00:00\", \"core\": {\"food\": \"chic\", \"c_expire_dt\": \"0001-01-01T00:00:00\"}},\n","            live={\"foo\": _v(\"1\"), \"core\": {\"food\": \"chic\"}},\n","        ),\n","    ],\n","    _create_schema(**UNION_SCHEMA, live=_ns(\"foo\")),\n",")\n","\n","compacted = compact_entities(spark_session, union)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3UvKilN31lmb","executionInfo":{"status":"ok","timestamp":1636651353121,"user_tz":0,"elapsed":1761,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}},"outputId":"716846aa-ca16-44ba-adcf-1e8cbd57892c"},"source":["union.collect()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(_dt='2020-01-01T00:00:04.0000', _compacted=None, date_created=None, date_updated='2020-01-01T00:00:04.0000', id='foo', version='1.0.0', live=Row(foo=Row(value='3'))),\n"," Row(_dt='2020-01-01T00:00:03.0000', _compacted=None, date_created=None, date_updated='2020-01-01T00:00:03.0000', id='foo', version='1.0.0', live=Row(foo=Row(value='2'))),\n"," Row(_dt='0', _compacted=True, date_created='2020-01-01T00:00:01.0000', date_updated='2020-01-01T00:00:02.0000', id='foo', version='1.0.0', live=Row(foo=Row(value='1'))),\n"," Row(_dt='0', _compacted=True, date_created='2020-01-01T00:00:01.0000', date_updated='2020-01-01T00:00:02.0000', id='chic', version='1.0.0', live=Row(foo=Row(value='1')))]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Q27N9OQ1fei","executionInfo":{"status":"ok","timestamp":1636651354239,"user_tz":0,"elapsed":1121,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}},"outputId":"aeb55b52-50ba-4b9c-d895-d927adcba19b"},"source":["compacted.collect()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(date_created='2020-01-01T00:00:01.0000', date_updated='2020-01-01T00:00:04.0000', id='foo', version='1.0.0', live=Row(foo=Row(value='3'))),\n"," Row(date_created='2020-01-01T00:00:01.0000', date_updated='2020-01-01T00:00:02.0000', id='chic', version='1.0.0', live=Row(foo=Row(value='1')))]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"t9GFYV40lX-_","executionInfo":{"status":"ok","timestamp":1636651354589,"user_tz":0,"elapsed":353,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}}},"source":["import pandas as pd\n","\n","df = pd.DataFrame([\n","        dict(\n","            _dt=_dt(4),\n","            id=\"foo\",\n","            version=\"1.0.0\",\n","            date_updated=_dt(4),\n","            live={\"foo\": _v(\"3\")},\n","            _compacted=False,\n","             date_created=_dt(1),\n","             c_action = None,\n","        ),\n","        dict(\n","            _dt=_dt(3),\n","            id=\"foo\",\n","            version=\"1.0.0\",\n","            date_updated=_dt(3),\n","            live={\"foo\": _v(\"2\")},\n","             date_created=_dt(1),\n","             _compacted=False,\n","             c_action = None\n","        ),\n","        dict(\n","            _dt=_dt(1),\n","            _compacted=True,\n","            id=\"foo\",\n","            version=\"1.0.0\",\n","            date_updated=_dt(2),\n","            date_created=_dt(1),\n","            live={\"foo\": _v(\"1\")},\n","             c_action = None\n","        ),\n","        dict(\n","            _dt=_dt(0),\n","            _compacted=True,\n","            id=\"chic\",\n","            version=\"1.0.0\",\n","            date_updated=_dt(2),\n","            date_created=_dt(1),\n","            live={\"foo\": _v(\"1\"), \"c_expire_dt\": \"0001-01-01T00:00:00\", \"core\": {\"food\": \"chic\", \"c_expire_dt\": \"0001-01-01T00:00:00\"}},\n","            # live={\"foo\": _v(\"1\"), \"core\": {\"food\": \"chic\"}},\n","             c_action = \"delete\"\n","        ),\n","    ])\n","\n","union = spark_session.createDataFrame(df)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":258},"id":"DT9SKZeQlieN","executionInfo":{"status":"ok","timestamp":1636651354590,"user_tz":0,"elapsed":17,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}},"outputId":"6977be7e-fcb9-408a-cc14-046fdd01e6d0"},"source":["df"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>_dt</th>\n","      <th>id</th>\n","      <th>version</th>\n","      <th>date_updated</th>\n","      <th>live</th>\n","      <th>_compacted</th>\n","      <th>date_created</th>\n","      <th>c_action</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020-01-01T00:00:04.0000</td>\n","      <td>foo</td>\n","      <td>1.0.0</td>\n","      <td>2020-01-01T00:00:04.0000</td>\n","      <td>{'foo': {'value': '3'}}</td>\n","      <td>False</td>\n","      <td>2020-01-01T00:00:01.0000</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2020-01-01T00:00:03.0000</td>\n","      <td>foo</td>\n","      <td>1.0.0</td>\n","      <td>2020-01-01T00:00:03.0000</td>\n","      <td>{'foo': {'value': '2'}}</td>\n","      <td>False</td>\n","      <td>2020-01-01T00:00:01.0000</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2020-01-01T00:00:01.0000</td>\n","      <td>foo</td>\n","      <td>1.0.0</td>\n","      <td>2020-01-01T00:00:02.0000</td>\n","      <td>{'foo': {'value': '1'}}</td>\n","      <td>True</td>\n","      <td>2020-01-01T00:00:01.0000</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2020-01-01T00:00:00.0000</td>\n","      <td>chic</td>\n","      <td>1.0.0</td>\n","      <td>2020-01-01T00:00:02.0000</td>\n","      <td>{'foo': {'value': '1'}, 'c_expire_dt': '0001-0...</td>\n","      <td>True</td>\n","      <td>2020-01-01T00:00:01.0000</td>\n","      <td>delete</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        _dt    id  ...              date_created c_action\n","0  2020-01-01T00:00:04.0000   foo  ...  2020-01-01T00:00:01.0000     None\n","1  2020-01-01T00:00:03.0000   foo  ...  2020-01-01T00:00:01.0000     None\n","2  2020-01-01T00:00:01.0000   foo  ...  2020-01-01T00:00:01.0000     None\n","3  2020-01-01T00:00:00.0000  chic  ...  2020-01-01T00:00:01.0000   delete\n","\n","[4 rows x 8 columns]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s3E8cYzAmCDd","executionInfo":{"status":"ok","timestamp":1636651355812,"user_tz":0,"elapsed":273,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}},"outputId":"8bf0c447-35d7-4a96-84d6-2de76a1b657b"},"source":["union.collect()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(_dt='2020-01-01T00:00:04.0000', id='foo', version='1.0.0', date_updated='2020-01-01T00:00:04.0000', live={'foo': {'value': '3'}}, _compacted=False, date_created='2020-01-01T00:00:01.0000', c_action=None),\n"," Row(_dt='2020-01-01T00:00:03.0000', id='foo', version='1.0.0', date_updated='2020-01-01T00:00:03.0000', live={'foo': {'value': '2'}}, _compacted=False, date_created='2020-01-01T00:00:01.0000', c_action=None),\n"," Row(_dt='2020-01-01T00:00:01.0000', id='foo', version='1.0.0', date_updated='2020-01-01T00:00:02.0000', live={'foo': {'value': '1'}}, _compacted=True, date_created='2020-01-01T00:00:01.0000', c_action=None),\n"," Row(_dt='2020-01-01T00:00:00.0000', id='chic', version='1.0.0', date_updated='2020-01-01T00:00:02.0000', live={'core': {'food': 'chic', 'c_expire_dt': '0001-01-01T00:00:00'}, 'foo': {'value': '1'}, 'c_expire_dt': None}, _compacted=True, date_created='2020-01-01T00:00:01.0000', c_action='delete')]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"sfPe4CfClhjo","executionInfo":{"status":"ok","timestamp":1636651356729,"user_tz":0,"elapsed":282,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}}},"source":["compacted = compact_entities(spark_session, union)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"PoUFhYxNo1Bs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636651357693,"user_tz":0,"elapsed":501,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}},"outputId":"b109f25e-e380-4370-cb03-d6a283dcbcb7"},"source":["compacted.dropna(\"any\", subset=\"id\").collect()"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(id='foo', version='1.0.0', date_updated='2020-01-01T00:00:04.0000', live={'foo': {'value': '3'}}, date_created='2020-01-01T00:00:01.0000', c_action=None)]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xNpuwsYDmBZs","executionInfo":{"status":"ok","timestamp":1636651358751,"user_tz":0,"elapsed":282,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}},"outputId":"332240ed-7804-4e72-bd02-c313f36087ca"},"source":["compacted.collect()"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(id='foo', version='1.0.0', date_updated='2020-01-01T00:00:04.0000', live={'foo': {'value': '3'}}, date_created='2020-01-01T00:00:01.0000', c_action=None)]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"CX_juDaX41ah","executionInfo":{"status":"ok","timestamp":1636651361012,"user_tz":0,"elapsed":331,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}}},"source":["# test c_expire_dt\n","import pandas as pd\n","\n","df = pd.DataFrame([\n","        dict(\n","            _dt=_dt(4),\n","            id=\"foo\",\n","            version=\"1.0.0\",\n","            date_updated=_dt(4),\n","            live={\"foo\": _v(\"3\"), \"c_expire_dt\": \"0001-01-01T00:00:00\"},\n","            _compacted=False,\n","            date_created=_dt(1),\n","            c_action = None,\n","            c_expire_dt = None,\n","        ),\n","        dict(\n","            _dt=_dt(3),\n","            id=\"foo\",\n","            version=\"1.0.0\",\n","            date_updated=_dt(3),\n","            live={\"foo\": _v(\"2\"), \"c_expire_dt\":None},\n","            date_created=_dt(1),\n","            _compacted=False,\n","            c_action = None,\n","            c_expire_dt = None,\n","        ),\n","        dict(\n","            _dt=_dt(1),\n","            _compacted=True,\n","            id=\"foo\",\n","            version=\"1.0.0\",\n","            date_updated=_dt(2),\n","            date_created=_dt(1),\n","            live={\"foo\": _v(\"1\"), \"c_expire_dt\":None},\n","            c_action = None,\n","            c_expire_dt = None,\n","        ),\n","        dict(\n","            _dt=_dt(0),\n","            _compacted=True,\n","            id=\"chic\",\n","            version=\"1.0.0\",\n","            date_updated=_dt(2),\n","            date_created=_dt(1),\n","            live={\"foo\": _v(\"1\"), \"c_expire_dt\": \"0001-01-01T00:00:00\", \"core\": {\"food\": \"chic\", \"c_expire_dt\": \"0001-01-01T00:00:00\"}},\n","            c_action = \"lol\",\n","            c_expire_dt = \"2201-01-01T00:00:00\"\n","        ),\n","    ])\n","\n","union = spark_session.createDataFrame(df)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3kyTA-AaATrO","executionInfo":{"status":"ok","timestamp":1636651361012,"user_tz":0,"elapsed":5,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}},"outputId":"ed1b14e2-554f-41c0-b4dc-8c71abcce8c1"},"source":["df.live[3]"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'c_expire_dt': '0001-01-01T00:00:00',\n"," 'core': {'c_expire_dt': '0001-01-01T00:00:00', 'food': 'chic'},\n"," 'foo': {'value': '1'}}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FA6Dlk9TIv2A","executionInfo":{"status":"ok","timestamp":1636651361307,"user_tz":0,"elapsed":3,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}},"outputId":"eb0a0727-b122-4f55-b141-3a59b6af01ec"},"source":["_ns(\"live\")"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StructType(List(StructField(live,StructType(List(StructField(value,StringType,true))),true)))"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CfxJfZD8F-8Z","executionInfo":{"status":"ok","timestamp":1636651363023,"user_tz":0,"elapsed":162,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}},"outputId":"7b992730-6e55-4bc1-dc5a-b8e518ab56dd"},"source":["union.printSchema()"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- _dt: string (nullable = true)\n"," |-- id: string (nullable = true)\n"," |-- version: string (nullable = true)\n"," |-- date_updated: string (nullable = true)\n"," |-- live: map (nullable = true)\n"," |    |-- key: string\n"," |    |-- value: map (valueContainsNull = true)\n"," |    |    |-- key: string\n"," |    |    |-- value: string (valueContainsNull = true)\n"," |-- _compacted: boolean (nullable = true)\n"," |-- date_created: string (nullable = true)\n"," |-- c_action: string (nullable = true)\n"," |-- c_expire_dt: string (nullable = true)\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"sczqAE59mhXT"},"source":["# Schema"]},{"cell_type":"code","metadata":{"id":"shlIx7WDlRBF","executionInfo":{"status":"ok","timestamp":1636651381812,"user_tz":0,"elapsed":170,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}}},"source":["from pyspark.sql.types import (\n","    ArrayType,\n","    BooleanType,\n","    NumericType,\n","    StringType,\n","    StructField,\n","    StructType,\n",")\n","\n","field_type = StructType(\n","    [\n","        # Value\n","        StructField(\"value\", StringType(), nullable=True),\n","        # c_expire_dt\n","        StructField(\"c_expire_dt\", StringType(), nullable=True)\n","    ]\n",")\n","\n","\n","def _v(value: Optional[str]) -> dict:\n","    return {\"value\": value}\n","\n","\n","def _dt(secs: int) -> str:\n","    return f\"2020-01-01T00:00:{secs:02}.000\"\n","\n","\n","def _expire_dt(secs: int) -> dict:\n","    return {\"c_expire_dt\": f\"2020-01-01T00:00:{secs:02}.000\"}\n","\n","\n","def _ns(*attrs):\n","    ns = StructType()\n","    for key in attrs:\n","        ns.add(key, field_type)\n","    return ns"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LMDcBN-gmdy9","executionInfo":{"status":"ok","timestamp":1636651382058,"user_tz":0,"elapsed":4,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}},"outputId":"fe3b7e81-fecc-4ebd-cbd2-f806fb00c0b2"},"source":["_ns(\"live\")"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StructType(List(StructField(live,StructType(List(StructField(value,StringType,true),StructField(c_expire_dt,StringType,true))),true)))"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"8KO61EP2mnr_","executionInfo":{"status":"ok","timestamp":1636651382496,"user_tz":0,"elapsed":3,"user":{"displayName":"Chet Sheng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy_Dk7Ahwv2lZiGE0sUFyBO_xe7OiTtIJ9Qlezaw=s64","userId":"02447232751254445182"}}},"source":["live={\"foo\": {\"value\", \"bar\"}}"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"ARQfzDCZBjVd"},"source":[""],"execution_count":null,"outputs":[]}]}